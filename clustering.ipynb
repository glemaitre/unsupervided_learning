{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328e473e",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "In this lecture, we will learn about clustering. First, we explain the general concept\n",
    "of clustering. Then, we implement the k-means algorithm from scratch. Finally, we use\n",
    "clustering in a couple of use cases.\n",
    "\n",
    "## Clustering, an unsupervised learning task\n",
    "\n",
    "Clustering is an unsupervised learning task. We first explain the difference between\n",
    "supervised and unsupervised learning. Let's start by loading the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9532812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "iris.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b8e16",
   "metadata": {},
   "source": [
    "\n",
    "This dataset contains 150 samples of flowers. The flower features are the folllowing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00509d5d",
   "metadata": {},
   "source": [
    "\n",
    "While the target corresponds to the flower species. To simplify the problem, we\n",
    "consider only two features. We select the petal length and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e946a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "selected_features = [\"petal length (cm)\", \"petal width (cm)\"]\n",
    "X = iris.data.loc[:, selected_features]\n",
    "y = pd.Series(iris.target_names, name=\"target\")[iris.target].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aacd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673233f1",
   "metadata": {},
   "source": [
    "\n",
    "In a supervised learning task, both `X` and `y` are used to train the estimator.\n",
    "Visually, we have the following representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "_ = sns.scatterplot(\n",
    "    data=pd.concat([X, y], axis=1),\n",
    "    x=selected_features[0],\n",
    "    y=selected_features[1],\n",
    "    hue=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8a823",
   "metadata": {},
   "source": [
    "\n",
    "Associated with each 2-dimensional sample, we have a category corresponding to the\n",
    "flower species. In an unsupervised learning task, we do not have the target\n",
    "information, and thus the following information at hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ab727",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(data=X, x=selected_features[0], y=selected_features[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45e996",
   "metadata": {},
   "source": [
    "The goal of clustering is to find some strucutre in the data and group samples\n",
    "together.\n",
    "\n",
    "Having this representation can be useful notably for:\n",
    "\n",
    "- exploring data and finding patterns;\n",
    "- visualizations;\n",
    "- as preprocessing of a supervised learning task.\n",
    "\n",
    "Now, let's go into details in a simple but common clustering algorithm: k-means.\n",
    "\n",
    "## K-means\n",
    "\n",
    "In this section, we guide you to implement an algorithm from scratch called k-means.\n",
    "The goal of k-means is to define k-centroids that will be iteratively updated such\n",
    "that the distance between the samples and the centroids is minimized.\n",
    "\n",
    "### Our own implementation\n",
    "\n",
    "*Using numpy, draw three data samples from `X` that are used as initialization\n",
    "centroids*. Hint: you can use the function `np.random.choice` to draw samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736aa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5dbd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "955d6178",
   "metadata": {},
   "source": [
    "\n",
    "*Plot the data samples and the centroids in a scatter plot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ae0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e062d562",
   "metadata": {},
   "source": [
    "\n",
    "Now, our job is to move those centroids such that the distance between the samples\n",
    "and the closest centroid is minimized.\n",
    "\n",
    "*Compute the distance between each sample in `X` and each centroid*. Hint: you can\n",
    "use the function `scipy.spatial.distance.cdist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd64e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7917e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_data_to_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc824b44",
   "metadata": {},
   "source": [
    "\n",
    "*Compute the averaged distance between each sample and the closest centroids.*\n",
    "\n",
    "In the next iteration, we are going to check that this distance is decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab706bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca18ad9a",
   "metadata": {},
   "source": [
    "\n",
    "*Compute the label of the closest centroids for each data samples*. Hint: you can use\n",
    "the method `np.argmin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51fb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9d39b77",
   "metadata": {},
   "source": [
    "\n",
    "*Plot the data samples with their associated labels, as well as the centroids in a\n",
    "scatter plot.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c122118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96391d01",
   "metadata": {},
   "source": [
    "\n",
    "Now, we go back to the start of algorithm and update the centroids to a better\n",
    "location. Indeed, we compute the mean location of the grouped samples.\n",
    "\n",
    "*Group the original data by labels and compute the mean sample for each group*. Hint:\n",
    "Be aware that you can leverage the original dataframe using `X.groupby(labels)` where\n",
    "`labels` corresponds to the labelled data from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2226f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "850304f5",
   "metadata": {},
   "source": [
    "\n",
    "*Compute again the distance between each sample and the new centroids, the averaged\n",
    "distance between each sample and the closest centroid, and the label of the closest\n",
    "centroids for each data samples*. Hint: it corresponds to the three previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61099a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22aeda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "429342d5",
   "metadata": {},
   "source": [
    "\n",
    "*Plot the data samples with their associated labels, as well as the centroids in a\n",
    "scatter plot.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc1d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0201efa6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "*Repeat the previous steps by executing the cells multiple times until the centroids\n",
    "do not move anymore.* Is the error still decreasing?\n",
    "\n",
    "*Wrap the previous steps in a function called `k_means` that takes as arguments the\n",
    "data `X`, the number of clusters `n_clusters`, and the number of iterations to do. It\n",
    "should return the labeled data and the centroids.*\n",
    "\n",
    "*Plot the data samples with their associated labels, as well as the centroids in a\n",
    "scatter plot.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df012c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0d8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7c6175",
   "metadata": {},
   "source": [
    "\n",
    "*By running several time the algorithm above, does the labels of the data samples are\n",
    "always the same?*\n",
    "\n",
    "*Does the centroids are always the same?*\n",
    "\n",
    "Since we define to have three centroids (or clusters), then we can make a direct\n",
    "comparison with the original target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bb4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8ab42b6",
   "metadata": {},
   "source": [
    "\n",
    "It is quite common to use a cluster metric that compare the results of the clustering\n",
    "with some actual target. The `adjusted_rand_score` is one of them. It will be equal to\n",
    "1 if the clustering is identical to the target (up to a permutation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "adjusted_rand_score(y, data_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70a939",
   "metadata": {},
   "source": [
    "\n",
    "*Repeat the previous experiment using 5 clusters instead of 3 clusters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e73c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2aa970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d57a3e7",
   "metadata": {},
   "source": [
    "\n",
    "*Instead of using your own implementation, use the `KMeans` class from scikit-learn\n",
    "and check that you obtain the similar results.* Bonus question: what does the warning\n",
    "message mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571218e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21c3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5f4839",
   "metadata": {},
   "source": [
    "\n",
    "### How to choose the number of clusters?\n",
    "\n",
    "From the previous experiment, we saw that we need to decide of the number of clusters\n",
    "to use. In practice, there is no perfect solution. A potential solution is to look at\n",
    "the inertia (the averaged dispersion of the data around each centroids) as a function\n",
    "of the number of clusters. Let's plot this curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d584e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = range(1, 15)\n",
    "intertia = [KMeans(n_clusters=k, n_init=1).fit(X).inertia_ for k in n_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(n_clusters, intertia, marker=\"o\")\n",
    "ax.set_xlabel(\"n_clusters\")\n",
    "_ = ax.set_ylabel(\"inertia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a6a35",
   "metadata": {},
   "source": [
    "\n",
    "In this plot, we search for the \"elbow\" point, i.e. the point where the inertia does\n",
    "not decrease significantly anymore. In this case, we could choose 3 or 4 clusters.\n",
    "\n",
    "Sometimes, we compute some metrics and make a grid-search to find the optimal score.\n",
    "\n",
    "Some clustering algorithms do not require to specify the number of clusters. For\n",
    "instance, the DBSCAN algorithm will find the number of clusters based on the density\n",
    "of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de08760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "data_labeled = dbscan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de27b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(\n",
    "    data=pd.concat([X, pd.Series(data_labeled, name=\"labels\")], axis=1),\n",
    "    x=selected_features[0],\n",
    "    y=selected_features[1],\n",
    "    hue=\"labels\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e107a",
   "metadata": {},
   "source": [
    "\n",
    "It is important to know that each clustering method comes with some assumptions\n",
    "regarding the definition of a cluster. We can have a look a the scikit-learn\n",
    "documentation:\n",
    "https://scikit-learn.org/dev/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py\n",
    "\n",
    "## Some applications of clustering\n",
    "\n",
    "Now, we are going to have a look to a couple of applications of clustering.\n",
    "\n",
    "### Semi-supervised learning\n",
    "\n",
    "In this section, we see how to use clustering to perform semi-supervised learning.\n",
    "Here, we want to use a supervised predictive model but we do not have enough labeled\n",
    "data. We will use clustering to help us at having more data.\n",
    "\n",
    "We will use the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26cad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0].reshape(8, 8), cmap=\"gray\")\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40554bfb",
   "metadata": {},
   "source": [
    "\n",
    "Let's first divide the data into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68662eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff835a",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's imagine that we only have 50 labeled samples in our training set. We\n",
    "separate our training set accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1712e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observed = 50\n",
    "X_observed = X_train[:n_observed]\n",
    "X_unlabelled = X_train[n_observed:]\n",
    "y_observed = y_train[:n_observed]\n",
    "y_unlabelled = y_train[n_observed:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71746c7f",
   "metadata": {},
   "source": [
    "\n",
    "*Create a predictive model made of `MinMaxScaler` and a `LogisticRegression`. Train\n",
    "it on the observed portion of the training set and evaluate its performance on the\n",
    "testing set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993836c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea35c4bc",
   "metadata": {},
   "source": [
    "\n",
    "We see that the performance is quite low. We will now use clustering to help us.\n",
    "*Use `KMeans` with 50 clusters to cluster the entire training set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 50\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=1).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd00115",
   "metadata": {},
   "source": [
    "\n",
    "*Use `KMeans.transform` to get the distance of each sample to each cluster. Then,\n",
    "find the closest sample to each cluster and select it as a prototype.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1bb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1659ad37",
   "metadata": {},
   "source": [
    "\n",
    "*Use the previous prototype to train a new predictive model and evaluate its\n",
    "performance on the testing set. Does the performance improve?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7838a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a6b5921",
   "metadata": {},
   "source": [
    "\n",
    "### Clustering as a preprocessing step\n",
    "\n",
    "A slightly different way of using clustering as a preprocessing step in the pipeline.\n",
    "Here, we compare two models, where one of the model will use `KMeans` and thus the\n",
    "distance of a sample to each cluster instead of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1886289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_with_clustering = make_pipeline(\n",
    "    KMeans(n_clusters=n_clusters, n_init=1),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=1_000),\n",
    ")\n",
    "model_without_clustering = make_pipeline(\n",
    "    MinMaxScaler(), LogisticRegression(max_iter=1_000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b3dde",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Accuracy of the model with clustering as preprocessing: \"\n",
    "    f\"{model_with_clustering.fit(X_train, y_train).score(X_test, y_test):.2f}\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy of the model without clustering as preprocessing: \"\n",
    "    f\"{model_without_clustering.fit(X_train, y_train).score(X_test, y_test):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093a923",
   "metadata": {},
   "source": [
    "\n",
    "*Can we conclude that the model using clustering as a preprocessing step is better\n",
    "than the other one?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb48095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "cv_results_with_clusterting = cross_validate(\n",
    "    model_with_clustering, X_train, y_train, cv=cv, n_jobs=-1\n",
    ")\n",
    "cv_results_without_clusterting = cross_validate(\n",
    "    model_without_clustering, X_train, y_train, cv=cv, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"With clustering\": cv_results_with_clusterting[\"test_score\"],\n",
    "        \"Without clustering\": cv_results_without_clusterting[\"test_score\"],\n",
    "    }\n",
    ").plot.box(whis=100)\n",
    "_ = plt.title(\"Accuracy of the model with and without clustering as preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1bbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
